{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a49be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastapi\n",
      "  Using cached fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting uvicorn[standard]\n",
      "  Using cached uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting starlette<0.48.0,>=0.40.0 (from fastapi)\n",
      "  Using cached starlette-0.47.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from fastapi)\n",
      "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting click>=7.0 (from uvicorn[standard])\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting h11>=0.8 (from uvicorn[standard])\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: colorama>=0.4 in .\\venv\\lib\\site-packages (from uvicorn[standard]) (0.4.6)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard])\n",
      "  Using cached httptools-0.6.4-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard])\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pyyaml>=5.1 (from uvicorn[standard])\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard])\n",
      "  Using cached watchfiles-1.1.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard])\n",
      "  Using cached websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Using cached scipy-1.16.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "  Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting anyio<5,>=3.6.2 (from starlette<0.48.0,>=0.40.0->fastapi)\n",
      "  Using cached anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
      "Using cached scikit_learn-1.7.1-cp312-cp312-win_amd64.whl (8.7 MB)\n",
      "Using cached numpy-2.3.2-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached httptools-0.6.4-cp312-cp312-win_amd64.whl (88 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached scipy-1.16.1-cp312-cp312-win_amd64.whl (38.5 MB)\n",
      "Using cached starlette-0.47.2-py3-none-any.whl (72 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Using cached watchfiles-1.1.0-cp312-cp312-win_amd64.whl (292 kB)\n",
      "Using cached websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Using cached uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: websockets, typing-extensions, threadpoolctl, sniffio, pyyaml, python-dotenv, numpy, joblib, idna, httptools, h11, click, annotated-types, uvicorn, typing-inspection, scipy, pydantic-core, anyio, watchfiles, starlette, scikit-learn, pydantic, fastapi\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.10.0 click-8.2.1 fastapi-0.116.1 h11-0.16.0 httptools-0.6.4 idna-3.10 joblib-1.5.1 numpy-2.3.2 pydantic-2.11.7 pydantic-core-2.33.2 python-dotenv-1.1.1 pyyaml-6.0.2 scikit-learn-1.7.1 scipy-1.16.1 sniffio-1.3.1 starlette-0.47.2 threadpoolctl-3.6.0 typing-extensions-4.14.1 typing-inspection-0.4.1 uvicorn-0.35.0 watchfiles-1.1.0 websockets-15.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install fastapi \"uvicorn[standard]\" scikit-learn numpy\n",
    "! pip install httpx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61418b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import List, Dict, Optional, Any\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel, Field\n",
    "from uuid import uuid4\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class PetitionPreferences(BaseModel):\n",
    "    field: Optional[str] = Field(None, description=\"Primary technical field, e.g., 'Artificial Intelligence'\")\n",
    "    priority: Optional[str] = Field(None, description=\"High/Medium/Low\")\n",
    "    review_style: Optional[str] = Field(None, description=\"Brief / Detailed / Line-by-line\")\n",
    "\n",
    "class SubmitPetitionRequest(BaseModel):\n",
    "    client_id: str\n",
    "    petition_text: str\n",
    "    preferences: Optional[PetitionPreferences] = None\n",
    "\n",
    "class MatchItem(BaseModel):\n",
    "    reviewer_id: str\n",
    "    name: str\n",
    "    expertise: List[str]\n",
    "    score: float\n",
    "    breakdown: Dict[str, float]\n",
    "\n",
    "class MatchResponse(BaseModel):\n",
    "    client_id: str\n",
    "    top_k: int\n",
    "    matches: List[MatchItem]\n",
    "\n",
    "class Reviewer(BaseModel):\n",
    "    reviewer_id: str\n",
    "    name: str\n",
    "    expertise_tags: List[str]\n",
    "    notes: Optional[str] = None\n",
    "    max_capacity: int = 5\n",
    "    current_load: int = 0  # for availability factor\n",
    "\n",
    "# petition_id to data\n",
    "PETITIONS: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "# client_id to [petition_ids]\n",
    "CLIENT_TO_PETITIONS: Dict[str, List[str]] = {}\n",
    "\n",
    "# reviewer_id to Reviewer\n",
    "REVIEWERS: Dict[str, Reviewer] = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d852ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "\n",
    "def normalize_tags(tags: List[str]) -> List[str]:\n",
    "    return [re.sub(r\"\\s+\", \" \", t.strip().lower()) for t in tags]\n",
    "\n",
    "def reviewer_corpus_text(r: Reviewer) -> str:\n",
    "    base = \" \".join(normalize_tags(r.expertise_tags))\n",
    "    return (base + \" \" + (r.notes or \"\")).strip()\n",
    "\n",
    "def petition_doc_text(petition_text: str, prefs: Optional[PetitionPreferences]) -> str:\n",
    "    field_part = (prefs.field if prefs and prefs.field else \"\")\n",
    "    return f\"{petition_text}\\n{field_part}\"\n",
    "\n",
    "def tag_overlap_score(petition_text: str, reviewer_tags: List[str]) -> float:\n",
    "    text = petition_text.lower()\n",
    "    tags = normalize_tags(reviewer_tags)\n",
    "    if not tags:\n",
    "        return 0.0\n",
    "    hits = sum(1 for t in tags if t in text)\n",
    "    return hits / len(tags)\n",
    "\n",
    "def availability_factor(current_load: int, max_capacity: int) -> float:\n",
    "    if max_capacity <= 0:\n",
    "        return 0.0\n",
    "    val = 1.0 - (current_load / max_capacity)\n",
    "    return max(0.0, min(1.0, val))\n",
    "\n",
    "def compute_scores_for_petition(petition_text: str, prefs: Optional[PetitionPreferences]) -> List[Dict[str, Any]]:\n",
    "    if not REVIEWERS:\n",
    "        return []\n",
    "\n",
    "    petition_doc = petition_doc_text(petition_text, prefs)\n",
    "    reviewer_docs = [reviewer_corpus_text(r) for r in REVIEWERS.values()]\n",
    "    corpus = [petition_doc] + reviewer_docs\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), max_features=5000)\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    p_vec = X[0]           # 1 x V\n",
    "    r_vecs = X[1:]         # R x V\n",
    "\n",
    "    # Cosine similarities\n",
    "    sims = cosine_similarity(p_vec, r_vecs).flatten()\n",
    "\n",
    "    # Prepare scores for each reviewer\n",
    "    results = []\n",
    "    for idx, (rid, r) in enumerate(REVIEWERS.items()):\n",
    "        content_similarity = float(sims[idx])  # already 0..1 for tf-idf cosine\n",
    "        exp_match = tag_overlap_score(petition_doc, r.expertise_tags)  # 0..1\n",
    "        avail = availability_factor(r.current_load, r.max_capacity)    # 0..1\n",
    "\n",
    "        # Weighted score\n",
    "        score = (0.5 * content_similarity) + (0.3 * exp_match) + (0.2 * avail)\n",
    "\n",
    "        results.append({\n",
    "            \"reviewer_id\": rid,\n",
    "            \"name\": r.name,\n",
    "            \"expertise\": r.expertise_tags,\n",
    "            \"score\": float(score),\n",
    "            \"breakdown\": {\n",
    "                \"content_similarity\": float(content_similarity),\n",
    "                \"expertise_match\": float(exp_match),\n",
    "                \"availability\": float(avail)\n",
    "            }\n",
    "        })\n",
    "    # Sort by score desc\n",
    "    results.sort(key=lambda d: d[\"score\"], reverse=True)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2baaf327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "app = FastAPI(title=\"Profile matching\", version=\"0.1.0\")\n",
    "\n",
    "@app.post(\"/submit-petition\")\n",
    "def submit_petition(req: SubmitPetitionRequest):\n",
    "    # Basic validation\n",
    "    if not req.client_id or not req.petition_text.strip():\n",
    "        raise HTTPException(status_code=400, detail=\"client_id and petition_text are required.\")\n",
    "\n",
    "    petition_id = str(uuid4())\n",
    "    PETITIONS[petition_id] = {\n",
    "        \"petition_id\": petition_id,\n",
    "        \"client_id\": req.client_id,\n",
    "        \"petition_text\": req.petition_text,\n",
    "        \"preferences\": req.preferences.dict() if req.preferences else None,\n",
    "        \"created_at\": datetime.datetime.now(datetime.UTC)\n",
    "    }\n",
    "    CLIENT_TO_PETITIONS.setdefault(req.client_id, []).append(petition_id)\n",
    "    return {\"status\": \"success\", \"message\": \"Petition submitted successfully\", \"petition_id\": petition_id}\n",
    "\n",
    "@app.get(\"/match/{client_id}\", response_model=MatchResponse)\n",
    "def match_reviewers(client_id: str, top_k: int = 5):\n",
    "    petition_ids = CLIENT_TO_PETITIONS.get(client_id)\n",
    "    if not petition_ids:\n",
    "        raise HTTPException(status_code=404, detail=\"No petition found for this client_id.\")\n",
    "\n",
    "    # Use the latest petition for this client\n",
    "    last_pid = petition_ids[-1]\n",
    "    pdata = PETITIONS[last_pid]\n",
    "\n",
    "    scores = compute_scores_for_petition(\n",
    "        petition_text=pdata[\"petition_text\"],\n",
    "        prefs=PetitionPreferences(**pdata[\"preferences\"]) if pdata[\"preferences\"] else None\n",
    "    )\n",
    "    if not scores:\n",
    "        return MatchResponse(client_id=client_id, top_k=0, matches=[])\n",
    "\n",
    "    matches = [\n",
    "        MatchItem(\n",
    "            reviewer_id=s[\"reviewer_id\"],\n",
    "            name=s[\"name\"],\n",
    "            expertise=s[\"expertise\"],\n",
    "            score=round(s[\"score\"], 4),\n",
    "            breakdown={k: round(v, 4) for k, v in s[\"breakdown\"].items()}\n",
    "        )\n",
    "        for s in scores[:max(1, top_k)]\n",
    "    ]\n",
    "    return MatchResponse(client_id=client_id, top_k=len(matches), matches=matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034dec0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([Reviewer(reviewer_id='rev001', name='Dr. Amina Rahman', expertise_tags=['NIW', 'Immigration Law', 'Artificial Intelligence', 'Machine Learning', 'National Security'], notes='NIW focus for AI/ML; published guidance on substantial merit & national importance.', max_capacity=6, current_load=2), Reviewer(reviewer_id='rev002', name='John Carter', expertise_tags=['NIW', 'Biomedical', 'Public Health', 'USCIS', 'Evidence Synthesis'], notes='Experienced with Letters of Recommendation and policy impact framing.', max_capacity=5, current_load=4), Reviewer(reviewer_id='rev003', name='Sophia Lee', expertise_tags=['NIW', 'Civil Engineering', 'Infrastructure', 'Transportation', 'Environmental Impact'], notes='Strong with national importance narratives for infrastructure and resilience.', max_capacity=4, current_load=1), Reviewer(reviewer_id='rev004', name='Miguel Alvarez', expertise_tags=['NIW', 'Economics', 'Entrepreneurship', 'Startup Policy', 'Commercialization'], notes='Focus on market impact, job creation, and commercialization arguments.', max_capacity=3, current_load=0)])\n"
     ]
    }
   ],
   "source": [
    "def seed_reviewers():\n",
    "    REVIEWERS.clear()\n",
    "    r1 = Reviewer(\n",
    "        reviewer_id=\"rev001\",\n",
    "        name=\"Dr. Amina Rahman\",\n",
    "        expertise_tags=[\"NIW\", \"Immigration Law\", \"Artificial Intelligence\", \"Machine Learning\", \"National Security\"],\n",
    "        notes=\"NIW focus for AI/ML; published guidance on substantial merit & national importance.\",\n",
    "        max_capacity=6,\n",
    "        current_load=2,\n",
    "    )\n",
    "    r2 = Reviewer(\n",
    "        reviewer_id=\"rev002\",\n",
    "        name=\"John Carter\",\n",
    "        expertise_tags=[\"NIW\", \"Biomedical\", \"Public Health\", \"USCIS\", \"Evidence Synthesis\"],\n",
    "        notes=\"Experienced with Letters of Recommendation and policy impact framing.\",\n",
    "        max_capacity=5,\n",
    "        current_load=4,\n",
    "    )\n",
    "    r3 = Reviewer(\n",
    "        reviewer_id=\"rev003\",\n",
    "        name=\"Sophia Lee\",\n",
    "        expertise_tags=[\"NIW\", \"Civil Engineering\", \"Infrastructure\", \"Transportation\", \"Environmental Impact\"],\n",
    "        notes=\"Strong with national importance narratives for infrastructure and resilience.\",\n",
    "        max_capacity=4,\n",
    "        current_load=1,\n",
    "    )\n",
    "    r4 = Reviewer(\n",
    "        reviewer_id=\"rev004\",\n",
    "        name=\"Miguel Alvarez\",\n",
    "        expertise_tags=[\"NIW\", \"Economics\", \"Entrepreneurship\", \"Startup Policy\", \"Commercialization\"],\n",
    "        notes=\"Focus on market impact, job creation, and commercialization arguments.\",\n",
    "        max_capacity=3,\n",
    "        current_load=0,\n",
    "    )\n",
    "\n",
    "    for r in (r1, r2, r3, r4):\n",
    "        REVIEWERS[r.reviewer_id] = r\n",
    "\n",
    "seed_reviewers()\n",
    "list(REVIEWERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd97e259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submit status: 200\n",
      "{'status': 'success', 'message': 'Petition submitted successfully', 'petition_id': '091e6511-0ce3-49fd-8a17-9a0919246614'}\n",
      "\n",
      "Match status: 200\n",
      "{'client_id': 'client_123', 'top_k': 3, 'matches': [{'reviewer_id': 'rev001', 'name': 'Dr. Amina Rahman', 'expertise': ['NIW', 'Immigration Law', 'Artificial Intelligence', 'Machine Learning', 'National Security'], 'score': 0.3355, 'breakdown': {'content_similarity': 0.1643, 'expertise_match': 0.4, 'availability': 0.6667}}, {'reviewer_id': 'rev003', 'name': 'Sophia Lee', 'expertise': ['NIW', 'Civil Engineering', 'Infrastructure', 'Transportation', 'Environmental Impact'], 'score': 0.2522, 'breakdown': {'content_similarity': 0.0844, 'expertise_match': 0.2, 'availability': 0.75}}, {'reviewer_id': 'rev004', 'name': 'Miguel Alvarez', 'expertise': ['NIW', 'Economics', 'Entrepreneurship', 'Startup Policy', 'Commercialization'], 'score': 0.2, 'breakdown': {'content_similarity': 0.0, 'expertise_match': 0.0, 'availability': 1.0}}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WALTON\\AppData\\Local\\Temp\\ipykernel_37268\\3309269642.py:16: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  \"preferences\": req.preferences.dict() if req.preferences else None,\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "from fastapi.testclient import TestClient\n",
    "\n",
    "client = TestClient(app)\n",
    "\n",
    "payload = {\n",
    "    \"client_id\": \"client_123\",\n",
    "    \"petition_text\": (\n",
    "        \"My research in artificial intelligence focuses on robust perception for autonomous systems \"\n",
    "        \"with applications in national security and critical infrastructure resilience. \"\n",
    "        \"I collaborate with US defense labs and have publications at NeurIPS and ICRA. \"\n",
    "        \"My work enables safer autonomous navigation and situational awareness.\"\n",
    "    ),\n",
    "    \"preferences\": {\n",
    "        \"field\": \"Artificial Intelligence, Autonomous Systems, National Security\",\n",
    "        \"priority\": \"High\",\n",
    "        \"review_style\": \"Detailed\"\n",
    "    }\n",
    "}\n",
    "resp_submit = client.post(\"/submit-petition\", json=payload)\n",
    "print(\"Submit status:\", resp_submit.status_code)\n",
    "print(resp_submit.json())\n",
    "\n",
    "resp_match = client.get(\"/match/client_123\", params={\"top_k\": 3})\n",
    "print(\"\\nMatch status:\", resp_match.status_code)\n",
    "print(resp_match.json())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
